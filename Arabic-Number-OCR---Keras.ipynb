{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of v6-NID_number_extraction_process.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOIeTHEgz3RM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# installing libs\n",
        "\n",
        "!pip install imutils\n",
        "!pip install imgaug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XtbyHBYzUFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this code help us to reupdate get repo. over existed one \n",
        "!ls\n",
        "!rm -r Google-Colaboratory-datasets\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKp7msJarrR-",
        "colab_type": "code",
        "outputId": "4619d975-722a-4d01-f524-9d9a2385291c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# cloning the dataset to work on it and do augmentation process on it  \n",
        "!git clone https://github.com/Rawash/Google-Colaboratory-datasets.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Google-Colaboratory-datasets' already exists and is not an empty directory.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcoQ94Q9_1jM",
        "colab_type": "code",
        "outputId": "accecb9d-921b-4661-b54e-2024847dd0e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Dropout, Flatten, Dense,BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import imgaug as ia\n",
        "from imgaug import augmenters as iaa\n",
        "import imutils\n",
        "\n",
        "input_shape = 64 \n",
        "no_classes = 10\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNreZi-ZmIti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset augmentation\n",
        "seq = iaa.Sequential([\n",
        "    iaa.Noop(), # horizontal flips\n",
        "    # Small gaussian blur with random sigma between 0 and 0.5.\n",
        "    # But we only blur about 50% of all images.\n",
        "    iaa.GaussianBlur(sigma=(0, 3)),\n",
        "    iaa.Sometimes(0.5,\n",
        "#       iaa.Invert(0.3),\n",
        "      iaa.Affine(\n",
        "        rotate=(-5, 5),\n",
        "        )\n",
        "    ),\n",
        "    iaa.Multiply((0.2,2)),\n",
        "    # Strengthen or weaken the contrast in each image.\n",
        "    iaa.ContrastNormalization((0.5, 1.5)),\n",
        "    # Add gaussian noise.\n",
        "    # For 50% of all images, we sample the noise once per pixel.\n",
        "    # For the other 50% of all images, we sample the noise per pixel AND\n",
        "    # channel. This can change the color (not only brightness) of the\n",
        "    # pixels.\n",
        "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.02*255), per_channel=0.2),\n",
        "    # Make some images brighter and some darker.\n",
        "    # In 20% of all cases, we sample the multiplier once per channel,\n",
        "    # which can end up changing the color of the images.\n",
        "    # Apply affine transformations to each image.\n",
        "    # Scale/zoom them, translate/move them, rotate them and shear them.\n",
        "    iaa.Affine(\n",
        "        scale={\"x\": (1, 1.7), \"y\": (1, 1.7)},\n",
        "\n",
        "    )\n",
        "], random_order=True) # apply augmenters in random order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFHboT0y_1Xu",
        "colab_type": "code",
        "outputId": "1548a505-5784-4418-f323-23e4c87d61a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "# dataset prebaration\n",
        "\n",
        "print('collecting dataset') \n",
        "numbersPath = glob.glob('./Google-Colaboratory-datasets/dataset/**/*')\n",
        "\n",
        "stack =[]\n",
        "def blure(image):\n",
        "    img = cv2.imread(image,0)\n",
        "    className = image.split('/')[-2][-1]\n",
        "    stack.append([img,className]) \n",
        "\n",
        "list(map(blure,numbersPath))\n",
        "\n",
        "\n",
        "\n",
        "X = [item[0] for item in stack]\n",
        "Y = [item[1] for item in stack]\n",
        "\n",
        "\n",
        "newX = []\n",
        "newY = []\n",
        "\n",
        "for i in range(15):\n",
        "  augImages = seq.augment_images(X)\n",
        "  for indx , n in enumerate(augImages):\n",
        "      newX.append(n)\n",
        "      newY.append(Y[indx])\n",
        "\n",
        "for indx , n in enumerate(X):\n",
        "    newX.append(n)\n",
        "    newY.append(Y[indx])\n",
        "\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "collecting dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmPw2_QrCM9T",
        "colab_type": "code",
        "outputId": "c0632a5b-a7bb-48aa-8585-0f55c0e654e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# spliting the dataset into testing and training data \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.array(newX), np.array(newY), test_size=0.25, random_state=42)\n",
        "\n",
        "print('dataset gethering finished , the trained is : ',len(X_train))\n",
        "\n",
        "\n",
        "# reshape for gray channel to (n, 64, 64, 1)\n",
        "X_train = X_train.reshape(X_train.shape[0], input_shape, input_shape, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], input_shape, input_shape, 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset gethering finished , the trained is :  297600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcKbm5yXEO6g",
        "colab_type": "code",
        "outputId": "3528da6f-768c-4c20-e581-bf01f32bcd10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(297600, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyPLVlmi_9jZ",
        "colab_type": "code",
        "outputId": "4e791cdb-8c57-4424-c6c9-3cc8572b7c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "\n",
        "### Modal architecture.\n",
        "\n",
        "print('model Init start')\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,(3,3),strides=1,input_shape=(input_shape,input_shape,1),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "          \n",
        "model.add(Conv2D(64,(3,3),input_shape=(ib nput_shape,input_shape,1),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "          \n",
        "model.add(Conv2D(128,(3,3),input_shape=(input_shape,input_shape,1),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=500,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(units = 250, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(units = 100, activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(units = no_classes, activation = 'softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model Init start\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 62, 62, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 29, 29, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               2304500   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 250)               125250    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 250)               1000      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               25100     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 2,551,932\n",
            "Trainable params: 2,550,232\n",
            "Non-trainable params: 1,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kIFQ-d1ABdK",
        "colab_type": "code",
        "outputId": "ea12d298-9ef3-4d82-ebed-5b2e950fe850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "\n",
        "## code compilation line \n",
        "print('compilation start')\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print('compilation ended')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compilation start\n",
            "compilation ended\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9PEDom1AGAp",
        "colab_type": "code",
        "outputId": "fa771735-98d4-488b-846d-87f56c747fe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "\n",
        "print('image augmantation process')\n",
        "\n",
        "parametars = dict(rescale = 1./255,\n",
        "              zca_whitening = True,\n",
        "              width_shift_range=0.3,\n",
        "              shear_range = 0.3,\n",
        "              zoom_range = 0.35,\n",
        "              validation_split=0.2,\n",
        "             )\n",
        "\n",
        "train_datagen = ImageDataGenerator(**parametars)\n",
        "\n",
        "validation_datagen = ImageDataGenerator(**parametars)\n",
        "\n",
        "\n",
        "validation_set = validation_datagen.flow(X_test, y_test,\n",
        "                                            batch_size = 100)\n",
        "training_set = train_datagen.flow(X_train, y_train, batch_size = 100)\n",
        "\n",
        "print('image augmantation process ended')\n",
        "\n",
        "model.fit_generator(training_set,\n",
        "                     steps_per_epoch=len(X_train) / 100,\n",
        "                     epochs=45,\n",
        "                     validation_data = validation_set,\n",
        "                     validation_steps = 300)\n",
        "\n",
        "# train_datagen.fit(images, augment=True, seed=seed)\n",
        "print('model started saving your prediction model')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image augmantation process\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:645: UserWarning: This ImageDataGenerator specifies `zca_whitening`, which overrides setting of `featurewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "image augmantation process ended\n",
            "Epoch 1/45\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:799: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/preprocessing/image.py:817: UserWarning: This ImageDataGenerator specifies `zca_whitening`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2975/2976 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9450"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2976/2976 [==============================] - 267s 90ms/step - loss: 0.1767 - acc: 0.9450 - val_loss: 0.0475 - val_acc: 0.9828\n",
            "Epoch 2/45\n",
            " 452/2976 [===>..........................] - ETA: 3:25 - loss: 0.0670 - acc: 0.9788"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2975/2976 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9809"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2976/2976 [==============================] - 264s 89ms/step - loss: 0.0602 - acc: 0.9809 - val_loss: 0.0411 - val_acc: 0.9850\n",
            "Epoch 3/45\n",
            " 453/2976 [===>..........................] - ETA: 3:26 - loss: 0.0558 - acc: 0.9819"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2975/2976 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9830"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2976/2976 [==============================] - 265s 89ms/step - loss: 0.0516 - acc: 0.9830 - val_loss: 0.0359 - val_acc: 0.9869\n",
            "Epoch 4/45\n",
            " 452/2976 [===>..........................] - ETA: 3:28 - loss: 0.0440 - acc: 0.9850"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2975/2976 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9842"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2976/2976 [==============================] - 263s 88ms/step - loss: 0.0470 - acc: 0.9842 - val_loss: 0.0390 - val_acc: 0.9863\n",
            "Epoch 5/45\n",
            " 452/2976 [===>..........................] - ETA: 3:25 - loss: 0.0478 - acc: 0.9840"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2975/2976 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9851"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2976/2976 [==============================] - 263s 88ms/step - loss: 0.0443 - acc: 0.9851 - val_loss: 0.0381 - val_acc: 0.9859\n",
            "Epoch 6/45\n",
            " 450/2976 [===>..........................] - ETA: 3:27 - loss: 0.0460 - acc: 0.9848"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2975/2976 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9855"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2976/2976 [==============================] - 266s 89ms/step - loss: 0.0427 - acc: 0.9855 - val_loss: 0.0329 - val_acc: 0.9878\n",
            "Epoch 7/45\n",
            " 450/2976 [===>..........................] - ETA: 3:28 - loss: 0.0382 - acc: 0.9864"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2975/2976 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9857"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2976/2976 [==============================] - 266s 89ms/step - loss: 0.0412 - acc: 0.9857 - val_loss: 0.0339 - val_acc: 0.9873\n",
            "Epoch 8/45\n",
            " 453/2976 [===>..........................] - ETA: 3:27 - loss: 0.0398 - acc: 0.9861"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2975/2976 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9863"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2976/2976 [==============================] - 265s 89ms/step - loss: 0.0394 - acc: 0.9863 - val_loss: 0.0322 - val_acc: 0.9878\n",
            "Epoch 9/45\n",
            " 452/2976 [===>..........................] - ETA: 3:26 - loss: 0.0400 - acc: 0.9860"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1389/2976 [=============>................] - ETA: 2:11 - loss: 0.0395 - acc: 0.9863"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PX6rJtzAV1Q",
        "colab_type": "code",
        "outputId": "513be1ec-253a-4ea4-c32b-b4228fed59bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# model started saving your prediction model\n",
        "print('model started saving your prediction model')\n",
        "\n",
        "model.save('ar_numbers_v6.h5')\n",
        "\n",
        " \n",
        "print('conguratolations you are free to use the classifier :)')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model started saving your prediction model\n",
            "conguratolations you are free to use the classifier :)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTGFWmDBN2Ta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# next code is nessisary for Goolge collab \n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6YK_BeKNT5z",
        "colab_type": "code",
        "outputId": "e62e7776-3615-428d-c40b-df44b5d1a783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# next code is nessisary for Goolge collab \n",
        "from google.colab import files\n",
        "# !cd Google-Colaboratory-datasets\n",
        "!ls\n",
        "files.download('ar_numbers_v6.h5') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ar_numbers_v6.h5  datalab  Google-Colaboratory-datasets\r\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}